# Implementa√ß√£o de Perceptron para Classifica√ß√£o Bin√°ria

Este projeto apresenta uma implementa√ß√£o do algoritmo Perceptron do zero, utilizando Python e NumPy, para resolver um problema de classifica√ß√£o bin√°ria em um espa√ßo 2D. O c√≥digo gera dados linearmente separ√°veis, treina o modelo Perceptron e, ao final, exibe a equa√ß√£o da reta de decis√£o aprendida, juntamente com uma visualiza√ß√£o gr√°fica.

## O Problema

O objetivo deste projeto √© responder √† seguinte quest√£o:

> Dado um conjunto de pontos em 2D, implemente um perceptron para classificar duas classes linearmente separ√°veis. Qual √© a equa√ß√£o da reta de decis√£o aprendida?

## Como Executar

### Pr√©-requisitos

Certifique-se de ter Python instalado. Voc√™ precisar√° das seguintes bibliotecas:

-   NumPy
-   Matplotlib

Voc√™ pode instal√°-las via pip:

```bash
pip install numpy matplotlib
```

### Execu√ß√£o

1.  Salve o c√≥digo em um arquivo, por exemplo, `perceptron_classifier.py`.
2.  Execute o script a partir do seu terminal:

```bash
python perceptron_classifier.py
```

## Fundamentos Te√≥ricos do Perceptron

Um Perceptron √© a unidade neural mais simples e serve como base para redes neurais mais complexas. Suas caracter√≠sticas principais s√£o:

-   **Sa√≠da bin√°ria**: A sa√≠da do neur√¥nio √© 0 ou 1.
-   **Classificador Linear**: N√£o utiliza uma fun√ß√£o de ativa√ß√£o n√£o-linear.

#### Regra de Decis√£o

A classifica√ß√£o de uma nova amostra **x** √© feita com base na seguinte regra, onde **w** s√£o os pesos e **b** √© o bias:

$$
y = \begin{cases} 
1 & \text{se } \mathbf{w} \cdot \mathbf{x} + b > 0 \\
0 & \text{se } \mathbf{w} \cdot \mathbf{x} + b \le 0 
\end{cases}
$$

#### A Fronteira de Decis√£o

A fronteira de decis√£o do Perceptron √© a linha (ou hiperplano, em mais dimens√µes) que separa as duas classes. Ela ocorre exatamente onde a entrada da fun√ß√£o de ativa√ß√£o √© zero:

$$w_1x_1 + w_2x_2 + b = 0$$

Essa equa√ß√£o pode ser reescrita na forma padr√£o de uma reta ($y = mx + c$), onde $x_2$ representa o eixo y e $x_1$ o eixo x:

$$x_2 = \left(-\frac{w_1}{w_2}\right)x_1 + \left(-\frac{b}{w_2}\right)$$

Onde:
-   **Inclina√ß√£o (Slope)** = $-w_1/w_2$
-   **Intercepto (Intercept)** = $-b/w_2$

#### Algoritmo de Treinamento

O objetivo do treinamento √© encontrar os valores de **w** e **b** que separam os dados corretamente. O algoritmo implementado segue estes passos:
1.  Inicializa os pesos **w** e o bias **b** (geralmente com zeros).
2.  Para cada exemplo de treinamento $(\mathbf{x}, y)$:
    a. Calcula a sa√≠da linear: $z = \mathbf{w} \cdot \mathbf{x} + b$.
    b. Prev√™ a classe $y'$ usando a regra de decis√£o.
    c. Se a previs√£o $y'$ estiver errada ($y' \neq y$):
        - Atualiza os pesos: $\mathbf{w} \leftarrow \mathbf{w} + \eta(y - y')\mathbf{x}$
        - Atualiza o bias: $b \leftarrow b + \eta(y - y')$
3.  Repete o passo 2 por um n√∫mero definido de itera√ß√µes ou at√© que n√£o hajam mais erros.

## An√°lise da Implementa√ß√£o

O script fornecido materializa esses conceitos da seguinte forma:
-   A classe **`Perceptron`** encapsula toda a l√≥gica, com o m√©todo **`fit()`** implementando o algoritmo de treinamento.
-   A fun√ß√£o **`get_decision_boundary_equation()`** extrai os pesos e o bias aprendidos para calcular e exibir a equa√ß√£o da reta de decis√£o.
-   A fun√ß√£o **`plot_results()`** visualiza os dados e a fronteira de decis√£o, provando graficamente que o Perceptron encontrou uma solu√ß√£o linear para o problema.

## Exemplo de Sa√≠da

Ao executar o script, a sa√≠da no terminal ser√° semelhante a esta (os valores exatos podem variar):

```
======================================================================
QUEST√ÉO 1: PERCEPTRON PARA CLASSIFICA√á√ÉO BIN√ÅRIA EM 2D
======================================================================

‚úì Dados gerados: 100 pontos, 50 da classe 0, 50 da classe 1
Convergiu na itera√ß√£o 4
‚úì Acur√°cia no conjunto de treinamento: 100.00%

======================================================================
EQUA√á√ÉO DA RETA DE DECIS√ÉO APRENDIDA:
======================================================================

üìê Forma Geral: 1.2583*x1 + 1.6311*x2 + -10.0211 = 0
üìê Forma Padr√£o: x2 = -0.7715*x1 + 6.1434

    Coeficientes:
    ‚Ä¢ Peso w‚ÇÅ = 1.2583
    ‚Ä¢ Peso w‚ÇÇ = 1.6311
    ‚Ä¢ Bias b  = -10.0211

    ‚Ä¢ Inclina√ß√£o (slope) = -0.7715
    ‚Ä¢ Intercepto y = 6.1434
```
Adicionalmente, uma janela ser√° exibida com os gr√°ficos da classifica√ß√£o e da converg√™ncia do erro.
